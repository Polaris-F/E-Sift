#!/usr/bin/env python3
"""
å¤–éƒ¨CUDAä¸Šä¸‹æ–‡ç®¡ç†ç‰ˆæœ¬çš„demo
ä½¿ç”¨PyCUDAè®¾ç½®ä¸Šä¸‹æ–‡å’Œstreamï¼Œç„¶åä¼ å…¥CUDA SIFTè¿›è¡Œå¤„ç†

å¯¹æ¯”æ ‡å‡†demo.pyï¼Œè¿™ä¸ªç‰ˆæœ¬çš„ç‰¹ç‚¹ï¼š
1. ä½¿ç”¨PyCUDAåˆå§‹åŒ–CUDAä¸Šä¸‹æ–‡
2. åˆ›å»ºPyCUDA streamå¹¶ä¼ é€’ç»™SIFTç»„ä»¶
3. å¯ç”¨å¤–éƒ¨ä¸Šä¸‹æ–‡ç®¡ç† (external_context=True)
4. ä¿æŒä¸demo.pyç›¸åŒçš„æµ‹è¯•æµç¨‹å’Œè®¡æ—¶
"""

import sys
import os
import cv2
import numpy as np
import time

# å¯¼å…¥PyCUDA
try:
    import pycuda.driver as cuda
    import pycuda.autoinit  # è‡ªåŠ¨åˆå§‹åŒ–CUDAä¸Šä¸‹æ–‡
    print("âœ“ PyCUDA initialized successfully")
except ImportError:
    print("âŒ PyCUDA not available. Please install PyCUDA:")
    print("   pip install pycuda")
    sys.exit(1)

# å¯¼å…¥CUDA SIFT
sys.path.insert(0, "/home/jetson/lhf/workspace_2/E-Sift/build/python")
import cuda_sift

# åˆ›å»ºPyCUDA stream
stream = cuda.Stream()
print(f"âœ“ PyCUDA stream created: handle={stream.handle}")

# é…ç½®å’Œç»„ä»¶åˆ›å»ºï¼ˆå¤–éƒ¨ä¸Šä¸‹æ–‡æ¨¡å¼ï¼‰
print("ğŸ”§ åˆå§‹åŒ–SIFTç»„ä»¶ (å¤–éƒ¨CUDAä¸Šä¸‹æ–‡æ¨¡å¼)...")
config = cuda_sift.SiftConfig("/home/jetson/lhf/workspace_2/E-Sift/config/test_config.txt")
print(f"   é…ç½®åŠ è½½: dog_threshold={config.dog_threshold}, max_features={config.max_features}")

# åˆ›å»ºå¤–éƒ¨ä¸Šä¸‹æ–‡æ¨¡å¼çš„æå–å™¨å’ŒåŒ¹é…å™¨
sift_extractor = cuda_sift.SiftExtractor(config, external_context=True)
matcher = cuda_sift.SiftMatcher(external_context=True)

# è®¾ç½®PyCUDA stream
sift_extractor.set_cuda_stream(stream.handle)
matcher.set_cuda_stream(stream.handle)

# éªŒè¯streamè®¾ç½®
ext_stream = sift_extractor.get_cuda_stream()
match_stream = matcher.get_cuda_stream()
print(f"âœ“ Streamè®¾ç½®å®Œæˆ: extractor={ext_stream}, matcher={match_stream}")

# åŠ è½½å›¾åƒ
print("ğŸ“¸ åŠ è½½æµ‹è¯•å›¾åƒ...")
image1_gray = cv2.imread("/home/jetson/lhf/workspace_2/E-Sift/data/img1.jpg", cv2.IMREAD_GRAYSCALE)
image2_gray = cv2.imread("/home/jetson/lhf/workspace_2/E-Sift/data/img2.jpg", cv2.IMREAD_GRAYSCALE)

image1_bgr = cv2.imread("/home/jetson/lhf/workspace_2/E-Sift/data/img1.jpg")
image2_bgr = cv2.imread("/home/jetson/lhf/workspace_2/E-Sift/data/img2.jpg")

if image1_gray is None or image2_gray is None:
    print("âŒ æ— æ³•åŠ è½½å›¾åƒæ–‡ä»¶")
    sys.exit(1)


print(f"âœ“ BGRå›¾åƒåŠ è½½æˆåŠŸ: img1={image1_bgr.shape}, img2={image2_bgr.shape}")
print(f"âœ“ ç°åº¦å›¾åƒåŠ è½½æˆåŠŸ: img1={image1_gray.shape}, img2={image2_gray.shape}")
print(f"  BGRæ•°æ®ç±»å‹: {image1_bgr.dtype}, èŒƒå›´: {image1_bgr.min()}-{image1_bgr.max()}")

# å½“å‰ä½¿ç”¨ç°åº¦å›¾åƒè¿›è¡Œæµ‹è¯•ï¼ˆBGRåŠŸèƒ½å¼€å‘å®Œæˆååˆ‡æ¢ï¼‰
image1 = image1_gray
image2 = image1_gray


# åŒæ­¥streamç¡®ä¿åˆå§‹åŒ–å®Œæˆ
stream.synchronize()
print("âœ“ CUDA streamåŒæ­¥å®Œæˆ")

print("\n" + "="*50)
print("ğŸš€ å¼€å§‹ç‰¹å¾æå–æµ‹è¯• (100æ¬¡warmup)")
print("="*50)

# ç‰¹å¾æå–æµ‹è¯•1 - ä¸demo.pyç›¸åŒçš„æµ‹è¯•æ¨¡å¼
print("\nğŸ“Š Image1 ç‰¹å¾æå–æ€§èƒ½æµ‹è¯•...")
for _ in range(100):
    start_time = time.time()
    features1 = sift_extractor.extract(image1)
    extract_time = (time.time() - start_time) * 1000

print(f"âœ“ image1 æå–åˆ° {features1['num_features']} ä¸ªç‰¹å¾ç‚¹ ({extract_time:.2f}ms)")

print("\nğŸ“Š Image2 ç‰¹å¾æå–æ€§èƒ½æµ‹è¯•...")
for _ in range(100):
    start_time = time.time()
    features2 = sift_extractor.extract(image2)
    extract_time2 = (time.time() - start_time) * 1000

print(f"âœ“ image2 æå–åˆ° {features2['num_features']} ä¸ªç‰¹å¾ç‚¹ ({extract_time2:.2f}ms)")

# åŒ¹é…å’Œå•åº”æ€§è®¡ç®—æµ‹è¯•
print("\nğŸ“Š åŒ¹é…å’Œå•åº”æ€§è®¡ç®—æµ‹è¯•...")
for _ in range(1):
    start_time = time.time()
    result = matcher.match_and_compute_homography(
        features1, features2,
        use_improve=False  # é€Ÿåº¦ä¼˜å…ˆ
    )
    match_time = (time.time() - start_time) * 1000

np.set_printoptions(suppress=True, precision=3)
print(f"âœ“ match_and_compute_homography (use_improve=False) å¾—åˆ° {result['num_inliers']} ä¸ªå†…ç‚¹ ({match_time:.2f}ms)")
print(f"  å•åº”æ€§å˜æ¢çŸ©é˜µ:\n{result['homography']}")

# é¢å¤–æµ‹è¯•ï¼šéªŒè¯å¤–éƒ¨ä¸Šä¸‹æ–‡æ¨¡å¼çš„ç‰¹æ€§
print("\n" + "="*50)
print("ğŸ” å¤–éƒ¨ä¸Šä¸‹æ–‡æ¨¡å¼éªŒè¯")
print("="*50)

# è·å–å½“å‰å‚æ•°
params = sift_extractor.get_params()
print("å½“å‰æå–å™¨å‚æ•°:")
for key, value in params.items():
    print(f"  {key}: {value}")

# æµ‹è¯•å‚æ•°åŠ¨æ€ä¿®æ”¹
print("\nğŸ”§ æµ‹è¯•å‚æ•°åŠ¨æ€ä¿®æ”¹...")
original_threshold = params['dog_threshold']
sift_extractor.set_params({'dog_threshold': 1.4})
print(f"âœ“ dog_threshold ä» {original_threshold} ä¿®æ”¹ä¸º 1.4")

# ç”¨ä¿®æ”¹åçš„å‚æ•°é‡æ–°æå–
features1_modified = sift_extractor.extract(image1)
print(f"âœ“ ä¿®æ”¹å‚æ•°å image1 æå–åˆ° {features1_modified['num_features']} ä¸ªç‰¹å¾ç‚¹")

# æ¢å¤åŸå§‹å‚æ•°
sift_extractor.set_params({'dog_threshold': original_threshold})
print(f"âœ“ dog_threshold æ¢å¤ä¸º {original_threshold}")

# æµ‹è¯•streamåŒæ­¥
print("\nğŸ”„ æµ‹è¯•æ˜¾å¼streamåŒæ­¥...")
stream.synchronize()
sift_extractor.synchronize()
matcher.synchronize()
print("âœ“ æ‰€æœ‰streamåŒæ­¥å®Œæˆ")

# æœ€ç»ˆæ€§èƒ½æ±‡æ€»
print("\n" + "="*50)
print("ğŸ“ˆ æ€§èƒ½æ±‡æ€»")
print("="*50)
print(f"Image1 ç‰¹å¾æå–: {features1['num_features']} features, {extract_time:.2f}ms")
print(f"Image2 ç‰¹å¾æå–: {features2['num_features']} features, {extract_time2:.2f}ms")
print(f"åŒ¹é…+å•åº”æ€§è®¡ç®—: {result['num_matches']} matches â†’ {result['num_inliers']} inliers, {match_time:.2f}ms")
print(f"æ€»å¤„ç†æ—¶é—´: {extract_time + extract_time2 + match_time:.2f}ms")

print("\nğŸ‰ å¤–éƒ¨CUDAä¸Šä¸‹æ–‡æ¨¡å¼æµ‹è¯•å®Œæˆï¼")
